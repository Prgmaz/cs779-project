{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n!gzip -d cc.en.300.bin.gz","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport time\nfrom torch import nn\nimport torch\nimport spacy\nimport fasttext\nfrom collections import Counter\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nfrom torchmetrics import Accuracy\nfrom datasets import load_dataset\nimport pickle\n\nenglish = spacy.load(\"en_core_web_sm\")\neng_tokenizer = english.tokenizer\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nVOCAB_SIZE=2000000\nNUM_LAYERS=4 # 8\nNUM_HEADS=6 # 10\nDROPOUT=0.1\nEMBEDDING_DIM=300","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-11T06:47:19.421636Z","iopub.execute_input":"2023-11-11T06:47:19.421963Z","iopub.status.idle":"2023-11-11T06:47:38.317449Z","shell.execute_reply.started":"2023-11-11T06:47:19.421937Z","shell.execute_reply":"2023-11-11T06:47:38.316427Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# RiddleSense dataset","metadata":{}},{"cell_type":"code","source":"with open(\"vocab.pkl\", \"rb\") as f:\n    word2idx = pickle.load(f)\n    idx2word = dict([(v, k) for k, v in word2idx.items()])\n    \nwith open(\"embedding.mat\", \"rb\") as f:\n    emb_mat = torch.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T06:47:42.495753Z","iopub.execute_input":"2023-11-11T06:47:42.496609Z","iopub.status.idle":"2023-11-11T06:47:57.587303Z","shell.execute_reply.started":"2023-11-11T06:47:42.496578Z","shell.execute_reply":"2023-11-11T06:47:57.586480Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def convert_to_sentence(tokens, idx2word):\n    sentence = []\n    for tok in tokens:\n        if tok not in [0, 1, 2]:\n            sentence.append(idx2word[tok])\n    return \" \".join(sentence)\n\ndef convert_sentences_to_tokens(source, tokenizer):\n    sentences = []\n    for doc in tokenizer.pipe(source):\n        sentences.append([token.text.lower() for token in doc])\n    return sentences","metadata":{"execution":{"iopub.status.busy":"2023-11-11T06:47:57.588822Z","iopub.execute_input":"2023-11-11T06:47:57.589194Z","iopub.status.idle":"2023-11-11T06:47:57.598156Z","shell.execute_reply.started":"2023-11-11T06:47:57.589153Z","shell.execute_reply":"2023-11-11T06:47:57.595929Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Training dataset","metadata":{}},{"cell_type":"code","source":"riddle_data = load_dataset(\"riddle_sense\")\nriddle_data = pd.DataFrame(riddle_data[\"train\"])\nriddle_data = riddle_data[riddle_data[\"answerKey\"] != 'E']\nriddle_data = riddle_data.reset_index()\nsecond_data = pd.DataFrame.from_records(riddle_data[\"choices\"])\nriddle_data[[\"choice1\", \"choice2\", \"choice3\", \"choice4\"]] = np.array(second_data[\"text\"].tolist())[:, :4]\nriddle_data[\"answer\"] = pd.Categorical(riddle_data[\"answerKey\"]).codes\nriddle_data = riddle_data.drop([\"index\", \"answerKey\", \"choices\"], axis=1)\nriddle_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:29:32.589061Z","iopub.execute_input":"2023-11-11T13:29:32.589950Z","iopub.status.idle":"2023-11-11T13:29:33.742054Z","shell.execute_reply.started":"2023-11-11T13:29:32.589916Z","shell.execute_reply":"2023-11-11T13:29:33.741144Z"},"trusted":true},"execution_count":123,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2467668b741248cf865ea86b48a8307f"}},"metadata":{}},{"execution_count":123,"output_type":"execute_result","data":{"text/plain":"                                            question choice1    choice2  \\\n0               What gets smaller as it gets fuller?     bit        put   \n1  Whats weightless, visible to the naked eye, an...  amoeba     vision   \n2  what is weightless, and colorless. . but when ...    hole  measuring   \n3  What is lighter then a feather, can be seen by...    hole       find   \n4  I am always Hungery, I must always be Fed.  th...    cyan       rust   \n\n  choice3  choice4  answer  \n0    hole     rice       2  \n1    hole  hydride       2  \n2    heft    color       0  \n3    dust   sclera       0  \n4  maroon    flame       3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>choice1</th>\n      <th>choice2</th>\n      <th>choice3</th>\n      <th>choice4</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What gets smaller as it gets fuller?</td>\n      <td>bit</td>\n      <td>put</td>\n      <td>hole</td>\n      <td>rice</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Whats weightless, visible to the naked eye, an...</td>\n      <td>amoeba</td>\n      <td>vision</td>\n      <td>hole</td>\n      <td>hydride</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>what is weightless, and colorless. . but when ...</td>\n      <td>hole</td>\n      <td>measuring</td>\n      <td>heft</td>\n      <td>color</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is lighter then a feather, can be seen by...</td>\n      <td>hole</td>\n      <td>find</td>\n      <td>dust</td>\n      <td>sclera</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I am always Hungery, I must always be Fed.  th...</td>\n      <td>cyan</td>\n      <td>rust</td>\n      <td>maroon</td>\n      <td>flame</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sen_data = pd.read_csv(\"/kaggle/input/cs779-brainteaser/SP_train.csv\")\nsen_data[\"answer\"] = sen_data[\"label\"]\nsen_data = sen_data.drop([\"Unnamed: 0\", \"label\"], axis=1)\nsen_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:29:33.743676Z","iopub.execute_input":"2023-11-11T13:29:33.743990Z","iopub.status.idle":"2023-11-11T13:29:33.762900Z","shell.execute_reply.started":"2023-11-11T13:29:33.743966Z","shell.execute_reply":"2023-11-11T13:29:33.762079Z"},"trusted":true},"execution_count":124,"outputs":[{"execution_count":124,"output_type":"execute_result","data":{"text/plain":"                                            question  \\\n0  Mr. and Mrs. Mustard have six daughters and ea...   \n1  The six daughters of Mr. and Mrs. Mustard each...   \n2  A chess team has five players, and each player...   \n3  A woman shoots her husband. Then she holds him...   \n4  An individual shoots their spouse. She continu...   \n\n                                             choice1  \\\n0  Some daughters get married and have their own ...   \n1  Some brothers were not loved by family and mov...   \n2                 Each player shares the same coach.   \n3   The woman gets arrested for murder after dinner.   \n4   The woman gets arrested for murder after dinner.   \n\n                                             choice2  \\\n0             Each daughter shares the same brother.   \n1  Some daughters get married and have their own ...   \n2  Some players are backups and not allowed to play.   \n3                      The woman gets a new partner.   \n4  The woman was a photographer. She shot a pictu...   \n\n                                             choice3         choice4  answer  \n0  Some brothers were not loved by family and mov...  None of above.       1  \n1             Each daughter shares the same brother.  None of above.       2  \n2                          Some coaches get a raise.  None of above.       0  \n3  The woman was a photographer. She shot a pictu...  None of above.       2  \n4                      The woman gets a new partner.  None of above.       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>choice1</th>\n      <th>choice2</th>\n      <th>choice3</th>\n      <th>choice4</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Mr. and Mrs. Mustard have six daughters and ea...</td>\n      <td>Some daughters get married and have their own ...</td>\n      <td>Each daughter shares the same brother.</td>\n      <td>Some brothers were not loved by family and mov...</td>\n      <td>None of above.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The six daughters of Mr. and Mrs. Mustard each...</td>\n      <td>Some brothers were not loved by family and mov...</td>\n      <td>Some daughters get married and have their own ...</td>\n      <td>Each daughter shares the same brother.</td>\n      <td>None of above.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A chess team has five players, and each player...</td>\n      <td>Each player shares the same coach.</td>\n      <td>Some players are backups and not allowed to play.</td>\n      <td>Some coaches get a raise.</td>\n      <td>None of above.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A woman shoots her husband. Then she holds him...</td>\n      <td>The woman gets arrested for murder after dinner.</td>\n      <td>The woman gets a new partner.</td>\n      <td>The woman was a photographer. She shot a pictu...</td>\n      <td>None of above.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>An individual shoots their spouse. She continu...</td>\n      <td>The woman gets arrested for murder after dinner.</td>\n      <td>The woman was a photographer. She shot a pictu...</td>\n      <td>The woman gets a new partner.</td>\n      <td>None of above.</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"word_data = pd.read_csv(\"/kaggle/input/cs779-brainteaser/WP_train.csv\")\nword_data[\"answer\"] = word_data[\"label\"]\nword_data = word_data.drop([\"Unnamed: 0\", \"label\"], axis=1)\nword_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:29:33.763875Z","iopub.execute_input":"2023-11-11T13:29:33.764123Z","iopub.status.idle":"2023-11-11T13:29:33.780390Z","shell.execute_reply.started":"2023-11-11T13:29:33.764101Z","shell.execute_reply":"2023-11-11T13:29:33.779594Z"},"trusted":true},"execution_count":125,"outputs":[{"execution_count":125,"output_type":"execute_result","data":{"text/plain":"                                            question          choice1  \\\n0          How do you spell COW in thirteen letters?  SEE OH DEREFORD   \n1         In thirteen letters, how do you spell COW?  SEE OH DEREFORD   \n2             How do you spell COB in seven letters?          COBCOBB   \n3  If eleven plus two equals one, what does nine ...            Four.   \n4  What does nine plus five equal if eleven plus ...           Three.   \n\n             choice2            choice3         choice4  answer  \n0  SEE O DOUBLE YOU.      COWCOWCOWCOWW  None of above.       1  \n1      COWCOWCOWCOWW  SEE O DOUBLE YOU.  None of above.       2  \n2            COBBLER          SEE O BEE  None of above.       2  \n3               Two.             Three.  None of above.       1  \n4               Two.              Four.  None of above.       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>choice1</th>\n      <th>choice2</th>\n      <th>choice3</th>\n      <th>choice4</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>How do you spell COW in thirteen letters?</td>\n      <td>SEE OH DEREFORD</td>\n      <td>SEE O DOUBLE YOU.</td>\n      <td>COWCOWCOWCOWW</td>\n      <td>None of above.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>In thirteen letters, how do you spell COW?</td>\n      <td>SEE OH DEREFORD</td>\n      <td>COWCOWCOWCOWW</td>\n      <td>SEE O DOUBLE YOU.</td>\n      <td>None of above.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>How do you spell COB in seven letters?</td>\n      <td>COBCOBB</td>\n      <td>COBBLER</td>\n      <td>SEE O BEE</td>\n      <td>None of above.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>If eleven plus two equals one, what does nine ...</td>\n      <td>Four.</td>\n      <td>Two.</td>\n      <td>Three.</td>\n      <td>None of above.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What does nine plus five equal if eleven plus ...</td>\n      <td>Three.</td>\n      <td>Two.</td>\n      <td>Four.</td>\n      <td>None of above.</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data = pd.concat([riddle_data, sen_data, word_data], axis=0)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:29:39.671206Z","iopub.execute_input":"2023-11-11T13:29:39.671578Z","iopub.status.idle":"2023-11-11T13:29:39.686420Z","shell.execute_reply.started":"2023-11-11T13:29:39.671548Z","shell.execute_reply":"2023-11-11T13:29:39.685537Z"},"trusted":true},"execution_count":127,"outputs":[{"execution_count":127,"output_type":"execute_result","data":{"text/plain":"                                            question choice1    choice2  \\\n0               What gets smaller as it gets fuller?     bit        put   \n1  Whats weightless, visible to the naked eye, an...  amoeba     vision   \n2  what is weightless, and colorless. . but when ...    hole  measuring   \n3  What is lighter then a feather, can be seen by...    hole       find   \n4  I am always Hungery, I must always be Fed.  th...    cyan       rust   \n\n  choice3  choice4  answer  \n0    hole     rice       2  \n1    hole  hydride       2  \n2    heft    color       0  \n3    dust   sclera       0  \n4  maroon    flame       3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>choice1</th>\n      <th>choice2</th>\n      <th>choice3</th>\n      <th>choice4</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What gets smaller as it gets fuller?</td>\n      <td>bit</td>\n      <td>put</td>\n      <td>hole</td>\n      <td>rice</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Whats weightless, visible to the naked eye, an...</td>\n      <td>amoeba</td>\n      <td>vision</td>\n      <td>hole</td>\n      <td>hydride</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>what is weightless, and colorless. . but when ...</td>\n      <td>hole</td>\n      <td>measuring</td>\n      <td>heft</td>\n      <td>color</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is lighter then a feather, can be seen by...</td>\n      <td>hole</td>\n      <td>find</td>\n      <td>dust</td>\n      <td>sclera</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I am always Hungery, I must always be Fed.  th...</td>\n      <td>cyan</td>\n      <td>rust</td>\n      <td>maroon</td>\n      <td>flame</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"question = convert_sentences_to_tokens(data[\"question\"], eng_tokenizer)\nchoice1 = convert_sentences_to_tokens(data[\"choice1\"], eng_tokenizer)\nchoice2 = convert_sentences_to_tokens(data[\"choice2\"], eng_tokenizer)\nchoice3 = convert_sentences_to_tokens(data[\"choice3\"], eng_tokenizer)\nchoice4 = convert_sentences_to_tokens(data[\"choice4\"], eng_tokenizer)\nlabels = data[\"answer\"].to_numpy().astype(np.uint8)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:29:45.507726Z","iopub.execute_input":"2023-11-11T13:29:45.508154Z","iopub.status.idle":"2023-11-11T13:29:46.068237Z","shell.execute_reply.started":"2023-11-11T13:29:45.508122Z","shell.execute_reply":"2023-11-11T13:29:46.067363Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"del riddle_data, sen_data, word_data, data","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:29:46.241730Z","iopub.execute_input":"2023-11-11T13:29:46.242179Z","iopub.status.idle":"2023-11-11T13:29:46.247841Z","shell.execute_reply.started":"2023-11-11T13:29:46.242147Z","shell.execute_reply":"2023-11-11T13:29:46.246877Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"class TrainDataset(DataLoader):\n    def __init__(self, question, choice1, choice2, choice3, choice4, label, randomize_place=False):\n        self.randomize_place = randomize_place\n        self.question = np.array(question, dtype=object)\n        self.choice1 = np.array(choice1, dtype=object)\n        self.choice2 = np.array(choice2, dtype=object)\n        self.choice3 = np.array(choice3, dtype=object)\n        self.choice4 = np.array(choice4, dtype=object)\n        self.label = np.array(label)\n    \n    def __len__(self):\n        return self.question.shape[0]\n    \n    def __getitem__(self, idx):\n        question = torch.tensor([word2idx.get(word, 3) for word in self.question[idx]])\n        choice1 = torch.tensor([word2idx.get(word, 3) for word in self.choice1[idx]])\n        choice2 = torch.tensor([word2idx.get(word, 3) for word in self.choice2[idx]])\n        choice3 = torch.tensor([word2idx.get(word, 3) for word in self.choice3[idx]])\n        choice4 = torch.tensor([word2idx.get(word, 3) for word in self.choice4[idx]])\n        if self.randomize_place:\n            ridx = np.argsort(np.random.randint(0, 256, 4))\n            label = torch.tensor([ridx[self.label[idx]]])\n            choice1, choice2, choice3, choice4 = np.array([choice1, choice2, choice3, choice4], dtype=object)[ridx]\n        else:\n            label = torch.tensor([self.label[idx]])\n        return question, choice1, choice2, choice3, choice4, label\n    \n    \nclass TestDataset(DataLoader):\n    def __init__(self, question, choice1, choice2, choice3, choice4, label=None):\n        self.question = np.array(question, dtype=object)\n        self.choice1 = np.array(choice1, dtype=object)\n        self.choice2 = np.array(choice2, dtype=object)\n        self.choice3 = np.array(choice3, dtype=object)\n        self.choice4 = np.array(choice4, dtype=object)\n        if label is not None:\n            self.label = np.array(label, dtype=object)\n        else:\n            self.label = None\n    \n    def __len__(self):\n        return self.question.shape[0]\n    \n    def __getitem__(self, idx):\n        question = torch.tensor([word2idx.get(word, 3) for word in self.question[idx]])\n        choice1 = torch.tensor([word2idx.get(word, 3) for word in self.choice1[idx]])\n        choice2 = torch.tensor([word2idx.get(word, 3) for word in self.choice2[idx]])\n        choice3 = torch.tensor([word2idx.get(word, 3) for word in self.choice3[idx]])\n        choice4 = torch.tensor([word2idx.get(word, 3) for word in self.choice4[idx]])\n        if self.label is not None:\n            label = torch.tensor([self.label[idx]])\n        else:\n            label = torch.tensor([0])\n        return question, choice1, choice2, choice3, choice4, label\n    \ndef pad_collate(batch):\n    (a, b, c, d, e, f) = zip(*batch)\n    a = nn.utils.rnn.pad_sequence(a, batch_first=True, padding_value=2)\n    b = nn.utils.rnn.pad_sequence(b, batch_first=True, padding_value=2)\n    c = nn.utils.rnn.pad_sequence(c, batch_first=True, padding_value=2)\n    d = nn.utils.rnn.pad_sequence(d, batch_first=True, padding_value=2)\n    e = nn.utils.rnn.pad_sequence(e, batch_first=True, padding_value=2)\n    f = torch.tensor(f)\n    return a, b, c, d, e, f\n\ndef test_pad_collate(batch):\n    (a, b, c, d, e) = zip(*batch)\n    a = nn.utils.rnn.pad_sequence(a, batch_first=True, padding_value=2)\n    b = nn.utils.rnn.pad_sequence(b, batch_first=True, padding_value=2)\n    c = nn.utils.rnn.pad_sequence(c, batch_first=True, padding_value=2)\n    d = nn.utils.rnn.pad_sequence(d, batch_first=True, padding_value=2)\n    e = nn.utils.rnn.pad_sequence(e, batch_first=True, padding_value=2)\n    return a, b, c, d, e","metadata":{"execution":{"iopub.status.busy":"2023-11-11T11:08:04.066806Z","iopub.execute_input":"2023-11-11T11:08:04.067125Z","iopub.status.idle":"2023-11-11T11:08:04.090197Z","shell.execute_reply.started":"2023-11-11T11:08:04.067099Z","shell.execute_reply":"2023-11-11T11:08:04.089221Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, d_model, dropout=DROPOUT, max_len=5000):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        position = torch.arange(max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n        pe = torch.zeros(1, max_len, d_model)\n        pe[0, :, 0::2] = torch.sin(position * div_term)\n        pe[0, :, 1::2] = torch.cos(position * div_term)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + self.pe[0, :x.size(1)]\n        return self.dropout(x)\n\n\nclass BrainTeaserModel(nn.Module):\n    def __init__(self, \n                 vocab_size=VOCAB_SIZE, \n                 embedding_dim=EMBEDDING_DIM, \n                 num_layers=NUM_LAYERS, \n                 num_heads=NUM_HEADS, \n                 dropout=DROPOUT, \n                 embed_mat=None, \n                 freeze=True,\n                 n_class=4,\n                 batch_first=True):\n        super().__init__()\n        \n        self.vocab_size = vocab_size\n        self.embedding_dim = embedding_dim\n        self.num_layers = num_layers\n        self.num_heads = num_heads\n        self.dropout_rate = dropout\n        self.freeze=freeze\n        self.n_class=n_class\n        self.batch_first=True\n        \n        if embed_mat is None:\n            self.embeddings = nn.Embedding(self.vocab_size, self.embedding_dim, padding_idx=2).to(\"cpu\")\n        else:\n            self.embeddings = nn.Embedding.from_pretrained(embed_mat, padding_idx=2, freeze=self.freeze).to(\"cpu\")\n        self.pos_embeddings = PositionalEncoding(self.embedding_dim, dropout=self.dropout_rate).to(DEVICE)\n\n        self.encoder_layer = nn.TransformerEncoderLayer(self.embedding_dim, nhead=self.num_heads, dropout=self.dropout_rate, batch_first=self.batch_first)\n        self.decoder_layer = nn.TransformerDecoderLayer(self.embedding_dim, nhead=self.num_heads, dropout=self.dropout_rate, batch_first=self.batch_first)\n        self.encoder1 = nn.TransformerEncoder(self.encoder_layer, self.num_layers).to(DEVICE)\n        self.decoder1 = nn.TransformerDecoder(self.decoder_layer, self.num_layers).to(DEVICE)\n        self.decoder2 = nn.TransformerDecoder(self.decoder_layer, self.num_layers).to(DEVICE)\n        self.decoder3 = nn.TransformerDecoder(self.decoder_layer, self.num_layers).to(DEVICE)\n        self.decoder4 = nn.TransformerDecoder(self.decoder_layer, self.num_layers).to(DEVICE)\n        self.linear1 = nn.LazyLinear(self.n_class).to(DEVICE)\n        \n    def forward(self, a, b, c, d, e):\n        a = self.pos_embeddings(self.embeddings(a.cpu()).cuda())\n        b = self.pos_embeddings(self.embeddings(b.cpu()).cuda())\n        c = self.pos_embeddings(self.embeddings(c.cpu()).cuda())\n        d = self.pos_embeddings(self.embeddings(d.cpu()).cuda())\n        e = self.pos_embeddings(self.embeddings(e.cpu()).cuda())\n        \n        a = self.encoder1(a)\n        b = self.decoder1(b, a).mean(dim=1)\n        c = self.decoder2(c, a).mean(dim=1)\n        d = self.decoder3(d, a).mean(dim=1)\n        e = self.decoder4(e, a).mean(dim=1)\n        x = torch.cat([b, c, d, e], 1)\n        x = self.linear1(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-11T11:08:04.728546Z","iopub.execute_input":"2023-11-11T11:08:04.729231Z","iopub.status.idle":"2023-11-11T11:08:04.748854Z","shell.execute_reply.started":"2023-11-11T11:08:04.729199Z","shell.execute_reply":"2023-11-11T11:08:04.747858Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"model = BrainTeaserModel(vocab_size=VOCAB_SIZE, \n                         embedding_dim=EMBEDDING_DIM, \n                         num_layers=NUM_LAYERS, \n                         num_heads=NUM_HEADS, \n                         dropout=0, \n                         embed_mat=emb_mat, \n                         freeze=True, \n                         batch_first=True)\nmodel.load_state_dict(torch.load(\"brain-teaser-4.pth\"))\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\ncriterion = nn.CrossEntropyLoss()\ndataset = TrainDataset(question, choice1, choice2, choice3, choice4, labels, randomize_place=False)\nsampler = torch.utils.data.RandomSampler(dataset, num_samples=50000)\ntraining_data = DataLoader(dataset, batch_size=5, collate_fn=pad_collate, sampler=sampler)\naccuracy = Accuracy(task=\"multiclass\", num_classes=4).to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:48:37.725058Z","iopub.execute_input":"2023-11-11T13:48:37.725641Z","iopub.status.idle":"2023-11-11T13:48:41.616064Z","shell.execute_reply.started":"2023-11-11T13:48:37.725585Z","shell.execute_reply":"2023-11-11T13:48:41.615046Z"},"trusted":true},"execution_count":185,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n  warnings.warn('Lazy modules are a new feature under heavy development '\n","output_type":"stream"}]},{"cell_type":"code","source":"EPOCHS=1000\nfor epoch in range(1, EPOCHS):\n    postfix = {\"loss\": 0, \"accuracy\": 0}\n    loss_val = 0\n    acc_val = 0\n    bar = tqdm(training_data, desc=f'Epoch {epoch}', postfix=postfix)\n    for idx, (A, B, C, D, E, F) in enumerate(bar):\n        A = A.to(DEVICE)\n        B = B.to(DEVICE)\n        C = C.to(DEVICE)\n        D = D.to(DEVICE)\n        E = E.to(DEVICE)\n        F = F.to(DEVICE)\n\n        model.train()\n        optimizer.zero_grad()\n        preds = model(A, B, C, D, E)\n        loss = criterion(preds, F.long())\n        loss.backward()\n        optimizer.step()\n\n        model.eval()\n        with torch.inference_mode():\n            if not np.isnan(loss.item()):\n                loss_val += loss.item()\n            acc_val += accuracy(preds, F).item()\n            postfix[\"loss\"] = loss_val / (idx + 1)\n            postfix[\"accuracy\"] = acc_val / (idx + 1)\n        bar.set_postfix(postfix)\n    torch.save(model.state_dict(), f\"brain-teaser-4.pth\")","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), f\"brain-teaser-4.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:53:08.050955Z","iopub.execute_input":"2023-11-11T13:53:08.051791Z","iopub.status.idle":"2023-11-11T13:53:21.022130Z","shell.execute_reply.started":"2023-11-11T13:53:08.051757Z","shell.execute_reply":"2023-11-11T13:53:21.021025Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"markdown","source":"# Validation","metadata":{}},{"cell_type":"code","source":"spval_data = pd.read_csv(\"/kaggle/input/cs779-brainteaser/SP_validation.csv\")\nspval_data[\"answer\"] = spval_data[\"label\"]\nspval_data = spval_data.drop([\"Unnamed: 0\", \"label\"], axis=1)\n\nsp_question = convert_sentences_to_tokens(spval_data[\"question\"], eng_tokenizer)\nsp_choice1 = convert_sentences_to_tokens(spval_data[\"choice1\"], eng_tokenizer)\nsp_choice2 = convert_sentences_to_tokens(spval_data[\"choice2\"], eng_tokenizer)\nsp_choice3 = convert_sentences_to_tokens(spval_data[\"choice3\"], eng_tokenizer)\nsp_choice4 = convert_sentences_to_tokens(spval_data[\"choice4\"], eng_tokenizer)\nsp_labels = spval_data[\"answer\"].to_numpy().astype(np.uint8)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:50:43.836266Z","iopub.execute_input":"2023-11-11T13:50:43.836635Z","iopub.status.idle":"2023-11-11T13:50:43.874540Z","shell.execute_reply.started":"2023-11-11T13:50:43.836606Z","shell.execute_reply":"2023-11-11T13:50:43.873801Z"},"trusted":true},"execution_count":187,"outputs":[]},{"cell_type":"code","source":"val_dataset = TestDataset(sp_question, sp_choice1, sp_choice2, sp_choice3, sp_choice4, sp_labels)\nval_data = DataLoader(val_dataset, batch_size=5, collate_fn=pad_collate)\n\nsp_data = []\nbar = tqdm(val_data, postfix={\"accuracy\": 0})\nacc = 0\nfor idx, (A, B, C, D, E, F) in enumerate(bar):\n    A = A.to(DEVICE)\n    B = B.to(DEVICE)\n    C = C.to(DEVICE)\n    D = D.to(DEVICE)\n    E = E.to(DEVICE)\n    F = F.to(DEVICE)\n    \n    preds = model(A, B, C, D, E)\n    preds = preds.argmax(1)\n    acc += accuracy(preds, F).item()\n    bar.set_postfix({\"accuracy\": acc / (idx + 1)})\n    \n    for i in range(len(preds)):\n        sp_data.append(preds[i].item())\n        \nsp_data = np.array(sp_data)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:50:44.062674Z","iopub.execute_input":"2023-11-11T13:50:44.063524Z","iopub.status.idle":"2023-11-11T13:50:44.645183Z","shell.execute_reply.started":"2023-11-11T13:50:44.063492Z","shell.execute_reply":"2023-11-11T13:50:44.644236Z"},"trusted":true},"execution_count":188,"outputs":[{"name":"stderr","text":"100%|██████████| 20/20 [00:00<00:00, 35.11it/s, accuracy=0.685]\n","output_type":"stream"}]},{"cell_type":"code","source":"wpval_data = pd.read_csv(\"/kaggle/input/cs779-brainteaser/WP_validation.csv\")\nwpval_data[\"answer\"] = wpval_data[\"label\"]\nwpval_data = wpval_data.drop([\"Unnamed: 0\", \"label\"], axis=1)\nwpval_data = wpval_data.iloc[2:]\n\nwp_question = convert_sentences_to_tokens(wpval_data[\"question\"], eng_tokenizer)\nwp_choice1 = convert_sentences_to_tokens(wpval_data[\"choice1\"], eng_tokenizer)\nwp_choice2 = convert_sentences_to_tokens(wpval_data[\"choice2\"], eng_tokenizer)\nwp_choice3 = convert_sentences_to_tokens(wpval_data[\"choice3\"], eng_tokenizer)\nwp_choice4 = convert_sentences_to_tokens(wpval_data[\"choice4\"], eng_tokenizer)\nwp_labels = wpval_data[\"answer\"].to_numpy().astype(np.uint8)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:50:44.646811Z","iopub.execute_input":"2023-11-11T13:50:44.647131Z","iopub.status.idle":"2023-11-11T13:50:44.670709Z","shell.execute_reply.started":"2023-11-11T13:50:44.647104Z","shell.execute_reply":"2023-11-11T13:50:44.669652Z"},"trusted":true},"execution_count":189,"outputs":[]},{"cell_type":"code","source":"val_dataset = TestDataset(wp_question, wp_choice1, wp_choice2, wp_choice3, wp_choice4, wp_labels)\nval_data = DataLoader(val_dataset, batch_size=5, collate_fn=pad_collate)\n\nwp_data = []\nbar = tqdm(val_data, postfix={\"accuracy\": 0})\nacc = 0\nfor idx, (A, B, C, D, E, F) in enumerate(bar):\n    A = A.to(DEVICE)\n    B = B.to(DEVICE)\n    C = C.to(DEVICE)\n    D = D.to(DEVICE)\n    E = E.to(DEVICE)\n    F = F.to(DEVICE)\n    \n    preds = model(A, B, C, D, E)\n    preds = preds.argmax(1)\n    acc += accuracy(preds, F).item()\n    bar.set_postfix({\"accuracy\": acc / (idx + 1)})\n    \n    for i in range(len(preds)):\n        wp_data.append(preds[i].item())\n        \nwp_data = np.array(wp_data)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:50:44.826661Z","iopub.execute_input":"2023-11-11T13:50:44.826990Z","iopub.status.idle":"2023-11-11T13:50:45.282464Z","shell.execute_reply.started":"2023-11-11T13:50:44.826963Z","shell.execute_reply":"2023-11-11T13:50:45.281488Z"},"trusted":true},"execution_count":190,"outputs":[{"name":"stderr","text":"100%|██████████| 16/16 [00:00<00:00, 36.08it/s, accuracy=0.6]  \n","output_type":"stream"}]},{"cell_type":"code","source":"results = []\n\ndef calculate_acc(pred, true):\n    return pred[pred == true].size / pred.size\n\noriginal_acc = calculate_acc(sp_data[0::3], sp_labels[0::3])\nsemantic_acc = calculate_acc(sp_data[1::3], sp_labels[1::3])\ncontext_acc = calculate_acc(sp_data[2::3], sp_labels[2::3])\n\noriginal_semantic_acc = 0\noriginal_semantic_context_acc = 0\nfor i in range(0, len(sp_data), 3):\n    original_semantic_acc += np.floor(calculate_acc(sp_data[i: i+2], sp_labels[i: i+2]))\n    original_semantic_context_acc += np.floor(calculate_acc(sp_data[i: i+3], sp_labels[i: i+3]))\noriginal_semantic_acc /= (len(sp_data) // 3)\noriginal_semantic_context_acc /= (len(sp_data) // 3)\ntotal_acc = calculate_acc(sp_data, sp_labels)\nresults.append([\"Sentence\", original_acc, semantic_acc, context_acc, original_semantic_acc, original_semantic_context_acc, total_acc])\nprint(\"Sentence\", original_acc, semantic_acc, context_acc, original_semantic_acc, original_semantic_context_acc, total_acc)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:51:45.353706Z","iopub.execute_input":"2023-11-11T13:51:45.354406Z","iopub.status.idle":"2023-11-11T13:51:45.365650Z","shell.execute_reply.started":"2023-11-11T13:51:45.354376Z","shell.execute_reply":"2023-11-11T13:51:45.364645Z"},"trusted":true},"execution_count":194,"outputs":[{"name":"stdout","text":"Sentence 0.7272727272727273 0.6666666666666666 0.6666666666666666 0.5151515151515151 0.36363636363636365 0.6868686868686869\n","output_type":"stream"}]},{"cell_type":"code","source":"def calculate_acc(pred, true):\n    return pred[pred == true].size / pred.size\n\noriginal_acc = calculate_acc(wp_data[0::3], wp_labels[0::3])\nsemantic_acc = calculate_acc(wp_data[1::3], wp_labels[1::3])\ncontext_acc = calculate_acc(wp_data[2::3], wp_labels[2::3])\n\noriginal_semantic_acc = 0\noriginal_semantic_context_acc = 0\nfor i in range(0, len(wp_data), 3):\n    original_semantic_acc += np.floor(calculate_acc(wp_data[i: i+2], wp_labels[i: i+2]))\n    original_semantic_context_acc += np.floor(calculate_acc(wp_data[i: i+3], wp_labels[i: i+3]))\noriginal_semantic_acc /= (len(wp_data) // 3)\noriginal_semantic_context_acc /= (len(wp_data) // 3)\ntotal_acc = calculate_acc(wp_data, wp_labels)\nresults.append([\"Word\", original_acc, semantic_acc, context_acc, original_semantic_acc, original_semantic_context_acc, total_acc])\nprint(\"Word\", original_acc, semantic_acc, context_acc, original_semantic_acc, original_semantic_context_acc, total_acc)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:52:02.284904Z","iopub.execute_input":"2023-11-11T13:52:02.285702Z","iopub.status.idle":"2023-11-11T13:52:02.295716Z","shell.execute_reply.started":"2023-11-11T13:52:02.285672Z","shell.execute_reply":"2023-11-11T13:52:02.294746Z"},"trusted":true},"execution_count":195,"outputs":[{"name":"stdout","text":"Word 0.5384615384615384 0.5384615384615384 0.7692307692307693 0.38461538461538464 0.3076923076923077 0.6153846153846154\n","output_type":"stream"}]},{"cell_type":"code","source":"results = pd.DataFrame(results, columns=[\"Type\", \"Original\", \"Semantic\", \"Context\", \"Original+Semantic\", \"Original+Semantic+Reconstruction\", \"Accuracy\"])\nresults.to_csv(\"results.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T13:52:14.666986Z","iopub.execute_input":"2023-11-11T13:52:14.667706Z","iopub.status.idle":"2023-11-11T13:52:14.674548Z","shell.execute_reply.started":"2023-11-11T13:52:14.667676Z","shell.execute_reply":"2023-11-11T13:52:14.673617Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
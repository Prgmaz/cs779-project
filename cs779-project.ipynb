{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n!gzip -d cc.en.300.bin.gz","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport time\nfrom torch import nn\nimport torch\nimport spacy\nimport fasttext\nfrom collections import Counter\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nfrom torchmetrics import Accuracy\nfrom datasets import load_dataset\nimport pickle\n\nenglish = spacy.load(\"en_core_web_sm\")\neng_tokenizer = english.tokenizer\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nVOCAB_SIZE=2000000\nNUM_LAYERS=4 # 8\nNUM_HEADS=6 # 10\nDROPOUT=0.1\nEMBEDDING_DIM=300","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-05T01:51:22.648064Z","iopub.execute_input":"2023-11-05T01:51:22.648399Z","iopub.status.idle":"2023-11-05T01:51:23.780119Z","shell.execute_reply.started":"2023-11-05T01:51:22.648371Z","shell.execute_reply":"2023-11-05T01:51:23.779154Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# os.remove(\"cc.en.300.bin.gz\")\n# os.remove(\"machine-translation-transformer.pth\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading data","metadata":{}},{"cell_type":"code","source":"data = np.load(\"/kaggle/input/cs779-brainteaser/SP-train.npy\", allow_pickle=True)\ndata = pd.DataFrame.from_records(data)\ndata = data.drop([\"answer\", \"distractor1\", \"distractor2\", \"distractor(unsure)\", \"choice_order\"], axis=1)\ndata[[\"choice1\", \"choice2\", \"choice3\", \"choice4\"]] = np.array(data[\"choice_list\"].to_list())\ndata = data.drop([\"choice_list\", \"id\"], axis=1)\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_data = np.load(\"/kaggle/input/cs779-brainteaser/SP_val_question_random.npy\", allow_pickle=True)\nval_data = pd.DataFrame.from_records(val_data)\nval_data[[\"choice1\", \"choice2\", \"choice3\", \"choice4\"]] = np.array(val_data[\"choice_list\"].to_list())\nval_data = val_data.drop([\"choice_list\"], axis=1)\nval_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing data","metadata":{}},{"cell_type":"code","source":"def build_vocab(ft, vocab_size, embedding_dim=EMBEDDING_DIM):\n    word2idx = {\"<SOS>\": 0, \"<EOS>\": 1, \"<PAD>\": 2, \"<UNK>\": 3}\n    idx2word = dict([(v, k) for k, v in word2idx.items()])\n    mat = torch.zeros((vocab_size, embedding_dim), dtype=torch.float, device=DEVICE)\n    count = 4\n    for word in ft.words:\n        word2idx[word] = count\n        idx2word[count] = word\n        mat[count] = torch.tensor(ft.get_word_vector(word))\n        count += 1\n        if count >= vocab_size:\n            break\n    return word2idx, idx2word, mat\n\nftmodel = fasttext.load_model(\"cc.en.300.bin\")\nword2idx, idx2word, emb_mat = build_vocab(ftmodel, VOCAB_SIZE)\ndel ftmodel","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"vocab.pkl\", \"wb\") as f:\n    pickle.dump(word2idx, f)\n\nwith open(\"embedding.mat\", \"wb\") as f:\n    torch.save(emb_mat, f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"vocab.pkl\", \"rb\") as f:\n    word2idx = pickle.load(f)\n    idx2word = dict([(v, k) for k, v in word2idx.items()])\n    \nwith open(\"embedding.mat\", \"rb\") as f:\n    emb_mat = torch.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T01:51:46.609443Z","iopub.execute_input":"2023-11-05T01:51:46.609824Z","iopub.status.idle":"2023-11-05T01:51:57.345359Z","shell.execute_reply.started":"2023-11-05T01:51:46.609794Z","shell.execute_reply":"2023-11-05T01:51:57.344546Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Tokenize data","metadata":{}},{"cell_type":"code","source":"def convert_to_sentence(tokens, idx2word):\n    sentence = []\n    for tok in tokens:\n        if tok not in [0, 1, 2]:\n            sentence.append(idx2word[tok])\n    return \" \".join(sentence)\n\ndef convert_sentences_to_tokens(source, tokenizer):\n    sentences = []\n    for doc in tokenizer.pipe(source):\n        sentences.append([token.text.lower() for token in doc])\n    return sentences","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = np.argsort(np.random.randint(0, 256, len(data)))\nidx, ridx = idx[:457], idx[457:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"question = convert_sentences_to_tokens(data[\"question\"].iloc[idx], eng_tokenizer)\nchoice1 = convert_sentences_to_tokens(data[\"choice1\"].iloc[idx], eng_tokenizer)\nchoice2 = convert_sentences_to_tokens(data[\"choice2\"].iloc[idx], eng_tokenizer)\nchoice3 = convert_sentences_to_tokens(data[\"choice3\"].iloc[idx], eng_tokenizer)\nchoice4 = convert_sentences_to_tokens(data[\"choice4\"].iloc[idx], eng_tokenizer)\nlabels = data[\"label\"].iloc[idx]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_question = convert_sentences_to_tokens(data[\"question\"].iloc[ridx], eng_tokenizer)\ntest_choice1 = convert_sentences_to_tokens(data[\"choice1\"].iloc[ridx], eng_tokenizer)\ntest_choice2 = convert_sentences_to_tokens(data[\"choice2\"].iloc[ridx], eng_tokenizer)\ntest_choice3 = convert_sentences_to_tokens(data[\"choice3\"].iloc[ridx], eng_tokenizer)\ntest_choice4 = convert_sentences_to_tokens(data[\"choice4\"].iloc[ridx], eng_tokenizer)\ntest_labels = data[\"label\"].iloc[ridx]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_question = convert_sentences_to_tokens(val_data[\"question\"], eng_tokenizer)\nval_choice1 = convert_sentences_to_tokens(val_data[\"choice1\"], eng_tokenizer)\nval_choice2 = convert_sentences_to_tokens(val_data[\"choice2\"], eng_tokenizer)\nval_choice3 = convert_sentences_to_tokens(val_data[\"choice3\"], eng_tokenizer)\nval_choice4 = convert_sentences_to_tokens(val_data[\"choice4\"], eng_tokenizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyzing dataset","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n\nsns.histplot(data[\"label\"], bins=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c = Counter()\nfor i in range(len(question)):\n    for j in question[i]:\n        c[j] += 1\n    for j in choice1[i]:\n        c[j] += 1\n    for j in choice2[i]:\n        c[j] += 1\n    for j in choice3[i]:\n        c[j] += 1\n    for j in choice4[i]:\n        c[j] += 1\n\nd = pd.DataFrame(c.most_common(50))\nplt.figure(figsize=(30, 10))\nsns.barplot(d, x=0, y=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class TrainDataset(DataLoader):\n    def __init__(self, question, choice1, choice2, choice3, choice4, label, randomize_place=False):\n        self.randomize_place = randomize_place\n        self.question = np.array(question, dtype=object)\n        self.choice1 = np.array(choice1, dtype=object)\n        self.choice2 = np.array(choice2, dtype=object)\n        self.choice3 = np.array(choice3, dtype=object)\n        self.choice4 = np.array(choice4, dtype=object)\n        self.label = np.array(label)\n    \n    def __len__(self):\n        return self.question.shape[0]\n    \n    def __getitem__(self, idx):\n        question = torch.tensor([word2idx.get(word, 3) for word in self.question[idx]])\n        choice1 = torch.tensor([word2idx.get(word, 3) for word in self.choice1[idx]])\n        choice2 = torch.tensor([word2idx.get(word, 3) for word in self.choice2[idx]])\n        choice3 = torch.tensor([word2idx.get(word, 3) for word in self.choice3[idx]])\n        choice4 = torch.tensor([word2idx.get(word, 3) for word in self.choice4[idx]])\n        if self.randomize_place:\n            ridx = np.argsort(np.random.randint(0, 256, 4))\n            label = torch.tensor([ridx[self.label[idx]]])\n            choice1, choice2, choice3, choice4 = np.array([choice1, choice2, choice3, choice4], dtype=object)[ridx]\n        else:\n            label = torch.tensor([self.label[idx]])\n        return question, choice1, choice2, choice3, choice4, label\n    \n    \nclass TestDataset(DataLoader):\n    def __init__(self, question, choice1, choice2, choice3, choice4, label=None):\n        self.question = np.array(question, dtype=object)\n        self.choice1 = np.array(choice1, dtype=object)\n        self.choice2 = np.array(choice2, dtype=object)\n        self.choice3 = np.array(choice3, dtype=object)\n        self.choice4 = np.array(choice4, dtype=object)\n        if label is not None:\n            self.label = np.array(label, dtype=object)\n        else:\n            self.label = None\n    \n    def __len__(self):\n        return self.question.shape[0]\n    \n    def __getitem__(self, idx):\n        question = torch.tensor([word2idx.get(word, 3) for word in self.question[idx]])\n        choice1 = torch.tensor([word2idx.get(word, 3) for word in self.choice1[idx]])\n        choice2 = torch.tensor([word2idx.get(word, 3) for word in self.choice2[idx]])\n        choice3 = torch.tensor([word2idx.get(word, 3) for word in self.choice3[idx]])\n        choice4 = torch.tensor([word2idx.get(word, 3) for word in self.choice4[idx]])\n        if self.label is not None:\n            label = torch.tensor([self.label[idx]])\n        else:\n            label = torch.tensor([0])\n        return question, choice1, choice2, choice3, choice4, label\n    \ndef pad_collate(batch):\n    (a, b, c, d, e, f) = zip(*batch)\n    a = nn.utils.rnn.pad_sequence(a, batch_first=True, padding_value=2)\n    b = nn.utils.rnn.pad_sequence(b, batch_first=True, padding_value=2)\n    c = nn.utils.rnn.pad_sequence(c, batch_first=True, padding_value=2)\n    d = nn.utils.rnn.pad_sequence(d, batch_first=True, padding_value=2)\n    e = nn.utils.rnn.pad_sequence(e, batch_first=True, padding_value=2)\n    f = torch.tensor(f)\n    return a, b, c, d, e, f\n\ndef test_pad_collate(batch):\n    (a, b, c, d, e) = zip(*batch)\n    a = nn.utils.rnn.pad_sequence(a, batch_first=True, padding_value=2)\n    b = nn.utils.rnn.pad_sequence(b, batch_first=True, padding_value=2)\n    c = nn.utils.rnn.pad_sequence(c, batch_first=True, padding_value=2)\n    d = nn.utils.rnn.pad_sequence(d, batch_first=True, padding_value=2)\n    e = nn.utils.rnn.pad_sequence(e, batch_first=True, padding_value=2)\n    return a, b, c, d, e","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# First Model","metadata":{}},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, d_model, dropout=DROPOUT, max_len=5000):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        position = torch.arange(max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n        pe = torch.zeros(1, max_len, d_model)\n        pe[0, :, 0::2] = torch.sin(position * div_term)\n        pe[0, :, 1::2] = torch.cos(position * div_term)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + self.pe[0, :x.size(1)]\n        return self.dropout(x)\n\n\nclass BrainTeaserModel(nn.Module):\n    def __init__(self, \n                 vocab_size=VOCAB_SIZE, \n                 embedding_dim=EMBEDDING_DIM, \n                 num_layers=NUM_LAYERS, \n                 num_heads=NUM_HEADS, \n                 dropout=DROPOUT, \n                 embed_mat=None, \n                 freeze=True,\n                 n_class=4,\n                 batch_first=True):\n        super().__init__()\n        \n        self.vocab_size = vocab_size\n        self.embedding_dim = embedding_dim\n        self.num_layers = num_layers\n        self.num_heads = num_heads\n        self.dropout_rate = dropout\n        self.freeze=freeze\n        self.n_class=n_class\n        self.batch_first=True\n        \n        if embed_mat is None:\n            self.embeddings = nn.Embedding(self.vocab_size, self.embedding_dim, padding_idx=2)\n        else:\n            self.embeddings = nn.Embedding.from_pretrained(embed_mat, padding_idx=2, freeze=self.freeze)\n        self.pos_embeddings = PositionalEncoding(self.embedding_dim, dropout=self.dropout_rate)\n\n        self.encoder_layer = nn.TransformerEncoderLayer(self.embedding_dim, nhead=self.num_heads, dropout=self.dropout_rate, batch_first=self.batch_first)\n        self.decoder_layer = nn.TransformerDecoderLayer(self.embedding_dim, nhead=self.num_heads, dropout=self.dropout_rate, batch_first=self.batch_first)\n        self.encoder1 = nn.TransformerEncoder(self.encoder_layer, self.num_layers)\n        self.decoder1 = nn.TransformerDecoder(self.decoder_layer, self.num_layers)\n        self.decoder2 = nn.TransformerDecoder(self.decoder_layer, self.num_layers)\n        self.decoder3 = nn.TransformerDecoder(self.decoder_layer, self.num_layers)\n        self.decoder4 = nn.TransformerDecoder(self.decoder_layer, self.num_layers)\n        self.linear1 = nn.LazyLinear(self.n_class)\n        \n    def forward(self, a, b, c, d, e):\n        a = self.pos_embeddings(self.embeddings(a))\n        b = self.pos_embeddings(self.embeddings(b))\n        c = self.pos_embeddings(self.embeddings(c))\n        d = self.pos_embeddings(self.embeddings(d))\n        e = self.pos_embeddings(self.embeddings(e))\n        \n        a = self.encoder1(a)\n        b = self.decoder1(b, a).mean(dim=1)\n        c = self.decoder2(c, a).mean(dim=1)\n        d = self.decoder3(d, a).mean(dim=1)\n        e = self.decoder4(e, a).mean(dim=1)\n#         x = torch.cat([a.mean(dim=1), b, c, d, e], 1)\n        x = torch.cat([b, c, d, e], 1)\n        x = self.linear1(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Instantiation","metadata":{}},{"cell_type":"code","source":"model = BrainTeaserModel(vocab_size=VOCAB_SIZE, \n                         embedding_dim=EMBEDDING_DIM, \n                         num_layers=NUM_LAYERS, \n                         num_heads=NUM_HEADS, \n                         dropout=DROPOUT, \n#                          embed_mat=emb_mat, \n                         freeze=True, \n                         batch_first=True).to(DEVICE)\nmodel.load_state_dict(torch.load(\"brain-teaser-1.pth\"))\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 2000*5, gamma=0.5)\ncriterion = nn.CrossEntropyLoss()\ndataset = TrainDataset(question, choice1, choice2, choice3, choice4, labels)\nsampler = torch.utils.data.RandomSampler(dataset, num_samples=10000)\ntraining_data = DataLoader(dataset, batch_size=5, collate_fn=pad_collate, sampler=sampler)\naccuracy = Accuracy(task=\"multiclass\", num_classes=4).to(DEVICE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"EPOCHS=1000\nfor epoch in range(1, EPOCHS):\n    postfix = {\"loss\": 0, \"accuracy\": 0}\n    loss_val = 0\n    acc_val = 0\n    bar = tqdm(training_data, desc=f'Epoch {epoch}', postfix=postfix)\n    for idx, (A, B, C, D, E, F) in enumerate(bar):\n        A = A.to(DEVICE)\n        B = B.to(DEVICE)\n        C = C.to(DEVICE)\n        D = D.to(DEVICE)\n        E = E.to(DEVICE)\n        F = F.to(DEVICE)\n\n        model.train()\n        optimizer.zero_grad()\n        preds = model(A, B, C, D, E)\n        loss = criterion(preds, F.long())\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        model.eval()\n        with torch.inference_mode():\n            if not np.isnan(loss.item()):\n                loss_val += loss.item()\n            acc_val += accuracy(preds, F).item()\n            postfix[\"loss\"] = loss_val / (idx + 1)\n            postfix[\"accuracy\"] = acc_val / (idx + 1)\n        bar.set_postfix(postfix)\n    torch.save(model.state_dict(), f\"brain-teaser-2.pth\")","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), f\"brain-teaser-2.pth\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = []\nbar = tqdm(test_data, postfix={\"accuracy\": 0})\nacc = 0\nfor idx, (A, B, C, D, E, F) in enumerate(bar):\n    A = A.to(DEVICE)\n    B = B.to(DEVICE)\n    C = C.to(DEVICE)\n    D = D.to(DEVICE)\n    E = E.to(DEVICE)\n    F = F.to(DEVICE)\n    \n    preds = model(A, B, C, D, E)\n    preds = preds.argmax(1)\n    acc += accuracy(preds, F.long()).item()\n    for i in range(len(preds)):\n        q = convert_to_sentence(A[i].cpu().numpy(), idx2word)\n        c1 = convert_to_sentence(B[i].cpu().numpy(), idx2word)\n        c2 = convert_to_sentence(C[i].cpu().numpy(), idx2word)\n        c3 = convert_to_sentence(D[i].cpu().numpy(), idx2word)\n        c4 = convert_to_sentence(E[i].cpu().numpy(), idx2word)\n        print(f\"Question: {q}\\n1. {c1}\\n2. {c2}\\n3. {c3}\\n4. {c4}\")\n        print(f\"Prediction: {preds[i].item()+1}\\t Correct: {F[i].item()+1}\\n\\n\")\n        data.append(str(preds[i].item()))\n    break\n    bar.set_postfix({\"accuracy\": acc / (idx + 1)})","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Race Dataset","metadata":{}},{"cell_type":"code","source":"race_data = load_dataset(\"race\", \"high\")\nrace_data = pd.DataFrame(race_data[\"train\"])\nrace_data[\"question\"] = \"Context: \"+ race_data[\"article\"] + \"\\nQuestion: \" + race_data[\"question\"]\nrace_data[[\"choice1\", \"choice2\", \"choice3\", \"choice4\"]] = race_data[\"options\"].tolist()\nrace_data[\"answer\"] = pd.Categorical(race_data[\"answer\"]).codes\nrace_data = race_data.drop([\"example_id\", \"options\", \"article\"], axis=1)\nrace_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"question = convert_sentences_to_tokens(race_data[\"question\"], eng_tokenizer)\nchoice1 = convert_sentences_to_tokens(race_data[\"choice1\"], eng_tokenizer)\nchoice2 = convert_sentences_to_tokens(race_data[\"choice2\"], eng_tokenizer)\nchoice3 = convert_sentences_to_tokens(race_data[\"choice3\"], eng_tokenizer)\nchoice4 = convert_sentences_to_tokens(race_data[\"choice4\"], eng_tokenizer)\nlabels = race_data[\"answer\"].to_numpy().astype(np.uint8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del race_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, d_model, dropout=DROPOUT, max_len=5000):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        position = torch.arange(max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n        pe = torch.zeros(1, max_len, d_model)\n        pe[0, :, 0::2] = torch.sin(position * div_term)\n        pe[0, :, 1::2] = torch.cos(position * div_term)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + self.pe[0, :x.size(1)]\n        return self.dropout(x)\n\n\nclass BrainTeaserModel(nn.Module):\n    def __init__(self, \n                 vocab_size=VOCAB_SIZE, \n                 embedding_dim=EMBEDDING_DIM, \n                 num_layers=NUM_LAYERS, \n                 num_heads=NUM_HEADS, \n                 dropout=DROPOUT, \n                 embed_mat=None, \n                 freeze=True,\n                 n_class=4,\n                 batch_first=True):\n        super().__init__()\n        \n        self.vocab_size = vocab_size\n        self.embedding_dim = embedding_dim\n        self.num_layers = num_layers\n        self.num_heads = num_heads\n        self.dropout_rate = dropout\n        self.freeze=freeze\n        self.n_class=n_class\n        self.batch_first=True\n        \n        if embed_mat is None:\n            self.embeddings = nn.Embedding(self.vocab_size, self.embedding_dim, padding_idx=2)\n        else:\n            self.embeddings = nn.Embedding.from_pretrained(embed_mat, padding_idx=2, freeze=self.freeze)\n        self.pos_embeddings = PositionalEncoding(self.embedding_dim, dropout=self.dropout_rate)\n\n        self.encoder_layer = nn.TransformerEncoderLayer(self.embedding_dim, nhead=self.num_heads, dropout=self.dropout_rate, batch_first=self.batch_first)\n        self.decoder_layer = nn.TransformerDecoderLayer(self.embedding_dim, nhead=self.num_heads, dropout=self.dropout_rate, batch_first=self.batch_first)\n        self.encoder1 = nn.TransformerEncoder(self.encoder_layer, self.num_layers)\n        self.decoder1 = nn.TransformerDecoder(self.decoder_layer, self.num_layers)\n        self.decoder2 = nn.TransformerDecoder(self.decoder_layer, self.num_layers)\n        self.decoder3 = nn.TransformerDecoder(self.decoder_layer, self.num_layers)\n        self.decoder4 = nn.TransformerDecoder(self.decoder_layer, self.num_layers)\n        self.linear1 = nn.LazyLinear(self.n_class)\n        \n    def forward(self, a, b, c, d, e):\n        a = self.pos_embeddings(self.embeddings(a))\n        b = self.pos_embeddings(self.embeddings(b))\n        c = self.pos_embeddings(self.embeddings(c))\n        d = self.pos_embeddings(self.embeddings(d))\n        e = self.pos_embeddings(self.embeddings(e))\n        \n        a = self.encoder1(a)\n        b = self.decoder1(b, a).mean(dim=1)\n        c = self.decoder2(c, a).mean(dim=1)\n        d = self.decoder3(d, a).mean(dim=1)\n        e = self.decoder4(e, a).mean(dim=1)\n#         x = torch.cat([a.mean(dim=1), b, c, d, e], 1)\n        x = torch.cat([b, c, d, e], 1)\n        x = self.linear1(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BrainTeaserModel(vocab_size=VOCAB_SIZE, \n                         embedding_dim=EMBEDDING_DIM, \n                         num_layers=NUM_LAYERS, \n                         num_heads=NUM_HEADS, \n                         dropout=DROPOUT, \n                         embed_mat=emb_mat, \n                         freeze=True, \n                         batch_first=True).to(DEVICE)\n# model.load_state_dict(torch.load(\"brain-teaser-2.pth\"))\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 50000, gamma=0.15)\ncriterion = nn.CrossEntropyLoss()\ndataset = TrainDataset(question, choice1, choice2, choice3, choice4, labels)\nsampler = torch.utils.data.RandomSampler(dataset, num_samples=50000)\ntraining_data = DataLoader(dataset, batch_size=5, collate_fn=pad_collate, sampler=sampler)\naccuracy = Accuracy(task=\"multiclass\", num_classes=4).to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T01:51:28.454899Z","iopub.execute_input":"2023-11-05T01:51:28.455210Z","iopub.status.idle":"2023-11-05T01:51:28.520203Z","shell.execute_reply.started":"2023-11-05T01:51:28.455156Z","shell.execute_reply":"2023-11-05T01:51:28.518988Z"},"trusted":true},"execution_count":11,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m BrainTeaserModel(vocab_size\u001b[38;5;241m=\u001b[39mVOCAB_SIZE, \n\u001b[1;32m      2\u001b[0m                          embedding_dim\u001b[38;5;241m=\u001b[39mEMBEDDING_DIM, \n\u001b[1;32m      3\u001b[0m                          num_layers\u001b[38;5;241m=\u001b[39mNUM_LAYERS, \n\u001b[1;32m      4\u001b[0m                          num_heads\u001b[38;5;241m=\u001b[39mNUM_HEADS, \n\u001b[1;32m      5\u001b[0m                          dropout\u001b[38;5;241m=\u001b[39mDROPOUT, \n\u001b[0;32m----> 6\u001b[0m                          embed_mat\u001b[38;5;241m=\u001b[39m\u001b[43memb_mat\u001b[49m, \n\u001b[1;32m      7\u001b[0m                          freeze\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m      8\u001b[0m                          batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# model.load_state_dict(torch.load(\"brain-teaser-2.pth\"))\u001b[39;00m\n\u001b[1;32m     10\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'emb_mat' is not defined"],"ename":"NameError","evalue":"name 'emb_mat' is not defined","output_type":"error"}]},{"cell_type":"code","source":"EPOCHS=1000\nfor epoch in range(1, EPOCHS):\n    postfix = {\"loss\": 0, \"accuracy\": 0}\n    loss_val = 0\n    acc_val = 0\n    bar = tqdm(training_data, desc=f'Epoch {epoch}', postfix=postfix)\n    for idx, (A, B, C, D, E, F) in enumerate(bar):\n        A = A.to(DEVICE)\n        B = B.to(DEVICE)\n        C = C.to(DEVICE)\n        D = D.to(DEVICE)\n        E = E.to(DEVICE)\n        F = F.to(DEVICE)\n\n        model.train()\n        optimizer.zero_grad()\n        preds = model(A, B, C, D, E)\n        loss = criterion(preds, F.long())\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        model.eval()\n        with torch.inference_mode():\n            if not np.isnan(loss.item()):\n                loss_val += loss.item()\n            acc_val += accuracy(preds, F).item()\n            postfix[\"loss\"] = loss_val / (idx + 1)\n            postfix[\"accuracy\"] = acc_val / (idx + 1)\n        bar.set_postfix(postfix)\n    torch.save(model.state_dict(), f\"brain-teaser-2.pth\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), f\"brain-teaser-2.pth\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for idx, (A, B, C, D, E, F) in enumerate(bar):\n    print(A[0].unique(return_counts=True))\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RiddleSense dataset","metadata":{}},{"cell_type":"code","source":"with open(\"vocab.pkl\", \"rb\") as f:\n    word2idx = pickle.load(f)\n    idx2word = dict([(v, k) for k, v in word2idx.items()])\n    \nwith open(\"embedding.mat\", \"rb\") as f:\n    emb_mat = torch.load(f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_to_sentence(tokens, idx2word):\n    sentence = []\n    for tok in tokens:\n        if tok not in [0, 1, 2]:\n            sentence.append(idx2word[tok])\n    return \" \".join(sentence)\n\ndef convert_sentences_to_tokens(source, tokenizer):\n    sentences = []\n    for doc in tokenizer.pipe(source):\n        sentences.append([token.text.lower() for token in doc])\n    return sentences","metadata":{"execution":{"iopub.status.busy":"2023-11-05T01:51:23.781888Z","iopub.execute_input":"2023-11-05T01:51:23.782498Z","iopub.status.idle":"2023-11-05T01:51:23.788552Z","shell.execute_reply.started":"2023-11-05T01:51:23.782462Z","shell.execute_reply":"2023-11-05T01:51:23.787605Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"riddle_data = load_dataset(\"riddle_sense\")\nriddle_data = pd.DataFrame(riddle_data[\"train\"])\nriddle_data = riddle_data[riddle_data[\"answerKey\"] != 'E']\nriddle_data = riddle_data.reset_index()\nsecond_data = pd.DataFrame.from_records(riddle_data[\"choices\"])\nriddle_data[[\"choice1\", \"choice2\", \"choice3\", \"choice4\"]] = np.array(second_data[\"text\"].tolist())[:, :4]\nriddle_data[\"answer\"] = pd.Categorical(riddle_data[\"answerKey\"]).codes\nriddle_data = riddle_data.drop([\"index\", \"answerKey\", \"choices\"], axis=1)\nriddle_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-05T01:51:23.789669Z","iopub.execute_input":"2023-11-05T01:51:23.789918Z","iopub.status.idle":"2023-11-05T01:51:26.748312Z","shell.execute_reply.started":"2023-11-05T01:51:23.789888Z","shell.execute_reply":"2023-11-05T01:51:26.747238Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.09k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23fda4c1ca2349539889e892d590a992"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a07e49d5e72c480a806f9cc4c4079434"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset riddle_sense/default (download: 1.99 MiB, generated: 1.09 MiB, post-processed: Unknown size, total: 3.08 MiB) to /root/.cache/huggingface/datasets/riddle_sense/default/0.1.0/1b311d24c97e1fd41975315faf11fd918a56db0289367a99944ef0fa3dfd6811...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"519c9054677d4961a7120146bc1d9eb2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.29M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8566846320594310b609d31155928fc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/375k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"403539ef96c0417482fe12c17b916077"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/414k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abad7bc0f09d481e9b544405bae99b78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1829920956f4f68b08fb326a6e60afb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/3510 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1021 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1184 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset riddle_sense downloaded and prepared to /root/.cache/huggingface/datasets/riddle_sense/default/0.1.0/1b311d24c97e1fd41975315faf11fd918a56db0289367a99944ef0fa3dfd6811. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"522444e5079d4a5da33835ce2e58d926"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                            question choice1    choice2  \\\n0               What gets smaller as it gets fuller?     bit        put   \n1  Whats weightless, visible to the naked eye, an...  amoeba     vision   \n2  what is weightless, and colorless. . but when ...    hole  measuring   \n3  What is lighter then a feather, can be seen by...    hole       find   \n4  I am always Hungery, I must always be Fed.  th...    cyan       rust   \n\n  choice3  choice4  answer  \n0    hole     rice       2  \n1    hole  hydride       2  \n2    heft    color       0  \n3    dust   sclera       0  \n4  maroon    flame       3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>choice1</th>\n      <th>choice2</th>\n      <th>choice3</th>\n      <th>choice4</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What gets smaller as it gets fuller?</td>\n      <td>bit</td>\n      <td>put</td>\n      <td>hole</td>\n      <td>rice</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Whats weightless, visible to the naked eye, an...</td>\n      <td>amoeba</td>\n      <td>vision</td>\n      <td>hole</td>\n      <td>hydride</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>what is weightless, and colorless. . but when ...</td>\n      <td>hole</td>\n      <td>measuring</td>\n      <td>heft</td>\n      <td>color</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is lighter then a feather, can be seen by...</td>\n      <td>hole</td>\n      <td>find</td>\n      <td>dust</td>\n      <td>sclera</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I am always Hungery, I must always be Fed.  th...</td>\n      <td>cyan</td>\n      <td>rust</td>\n      <td>maroon</td>\n      <td>flame</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sen_data = np.load(\"/kaggle/input/cs779-brainteaser/SP-train.npy\", allow_pickle=True)\nsen_data = pd.DataFrame.from_records(sen_data)\nsen_data = sen_data.drop([\"answer\", \"distractor1\", \"distractor2\", \"distractor(unsure)\", \"choice_order\"], axis=1)\nsen_data[[\"choice1\", \"choice2\", \"choice3\", \"choice4\"]] = np.array(sen_data[\"choice_list\"].to_list())\nsen_data[\"answer\"] = sen_data[\"label\"]\nsen_data = sen_data.drop([\"choice_list\", \"id\", \"label\"], axis=1)\nsen_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-05T01:51:26.751016Z","iopub.execute_input":"2023-11-05T01:51:26.751399Z","iopub.status.idle":"2023-11-05T01:51:26.786227Z","shell.execute_reply.started":"2023-11-05T01:51:26.751365Z","shell.execute_reply":"2023-11-05T01:51:26.785242Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                            question  \\\n0  Mr. and Mrs. Mustard have six daughters and ea...   \n1  The six daughters of Mr. and Mrs. Mustard each...   \n2  A chess team has five players, and each player...   \n3  A woman shoots her husband. Then she holds him...   \n4  An individual shoots their spouse. She continu...   \n\n                                             choice1  \\\n0  Some daughters get married and have their own ...   \n1  Some brothers were not loved by family and mov...   \n2                 Each player shares the same coach.   \n3   The woman gets arrested for murder after dinner.   \n4   The woman gets arrested for murder after dinner.   \n\n                                             choice2  \\\n0             Each daughter shares the same brother.   \n1  Some daughters get married and have their own ...   \n2  Some players are backups and not allowed to play.   \n3                      The woman gets a new partner.   \n4  The woman was a photographer. She shot a pictu...   \n\n                                             choice3         choice4  answer  \n0  Some brothers were not loved by family and mov...  None of above.       1  \n1             Each daughter shares the same brother.  None of above.       2  \n2                          Some coaches get a raise.  None of above.       0  \n3  The woman was a photographer. She shot a pictu...  None of above.       2  \n4                      The woman gets a new partner.  None of above.       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>choice1</th>\n      <th>choice2</th>\n      <th>choice3</th>\n      <th>choice4</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Mr. and Mrs. Mustard have six daughters and ea...</td>\n      <td>Some daughters get married and have their own ...</td>\n      <td>Each daughter shares the same brother.</td>\n      <td>Some brothers were not loved by family and mov...</td>\n      <td>None of above.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The six daughters of Mr. and Mrs. Mustard each...</td>\n      <td>Some brothers were not loved by family and mov...</td>\n      <td>Some daughters get married and have their own ...</td>\n      <td>Each daughter shares the same brother.</td>\n      <td>None of above.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A chess team has five players, and each player...</td>\n      <td>Each player shares the same coach.</td>\n      <td>Some players are backups and not allowed to play.</td>\n      <td>Some coaches get a raise.</td>\n      <td>None of above.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A woman shoots her husband. Then she holds him...</td>\n      <td>The woman gets arrested for murder after dinner.</td>\n      <td>The woman gets a new partner.</td>\n      <td>The woman was a photographer. She shot a pictu...</td>\n      <td>None of above.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>An individual shoots their spouse. She continu...</td>\n      <td>The woman gets arrested for murder after dinner.</td>\n      <td>The woman was a photographer. She shot a pictu...</td>\n      <td>The woman gets a new partner.</td>\n      <td>None of above.</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"word_data = np.load(\"/kaggle/input/cs779-brainteaser/WP-train.npy\", allow_pickle=True)\nword_data = pd.DataFrame.from_records(word_data)\nword_data = word_data.drop([\"answer\", \"distractor1\", \"distractor2\", \"distractor(unsure)\", \"choice_order\"], axis=1)\nword_data[[\"choice1\", \"choice2\", \"choice3\", \"choice4\"]] = np.array(word_data[\"choice_list\"].to_list())\nword_data[\"answer\"] = word_data[\"label\"]\nword_data = word_data.drop([\"choice_list\", \"id\", \"label\"], axis=1)\nword_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-05T01:51:26.787630Z","iopub.execute_input":"2023-11-05T01:51:26.788037Z","iopub.status.idle":"2023-11-05T01:51:26.821951Z","shell.execute_reply.started":"2023-11-05T01:51:26.788001Z","shell.execute_reply":"2023-11-05T01:51:26.820984Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                            question          choice1  \\\n0          How do you spell COW in thirteen letters?  SEE OH DEREFORD   \n1         In thirteen letters, how do you spell COW?  SEE OH DEREFORD   \n2             How do you spell COB in seven letters?          COBCOBB   \n3  If eleven plus two equals one, what does nine ...            Four.   \n4  What does nine plus five equal if eleven plus ...           Three.   \n\n             choice2            choice3         choice4  answer  \n0  SEE O DOUBLE YOU.      COWCOWCOWCOWW  None of above.       1  \n1      COWCOWCOWCOWW  SEE O DOUBLE YOU.  None of above.       2  \n2            COBBLER          SEE O BEE  None of above.       2  \n3               Two.             Three.  None of above.       1  \n4               Two.              Four.  None of above.       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>choice1</th>\n      <th>choice2</th>\n      <th>choice3</th>\n      <th>choice4</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>How do you spell COW in thirteen letters?</td>\n      <td>SEE OH DEREFORD</td>\n      <td>SEE O DOUBLE YOU.</td>\n      <td>COWCOWCOWCOWW</td>\n      <td>None of above.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>In thirteen letters, how do you spell COW?</td>\n      <td>SEE OH DEREFORD</td>\n      <td>COWCOWCOWCOWW</td>\n      <td>SEE O DOUBLE YOU.</td>\n      <td>None of above.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>How do you spell COB in seven letters?</td>\n      <td>COBCOBB</td>\n      <td>COBBLER</td>\n      <td>SEE O BEE</td>\n      <td>None of above.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>If eleven plus two equals one, what does nine ...</td>\n      <td>Four.</td>\n      <td>Two.</td>\n      <td>Three.</td>\n      <td>None of above.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What does nine plus five equal if eleven plus ...</td>\n      <td>Three.</td>\n      <td>Two.</td>\n      <td>Four.</td>\n      <td>None of above.</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data = pd.concat([riddle_data, sen_data, word_data], axis=0)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-05T01:51:26.823233Z","iopub.execute_input":"2023-11-05T01:51:26.823547Z","iopub.status.idle":"2023-11-05T01:51:26.836878Z","shell.execute_reply.started":"2023-11-05T01:51:26.823521Z","shell.execute_reply":"2023-11-05T01:51:26.835943Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                            question choice1    choice2  \\\n0               What gets smaller as it gets fuller?     bit        put   \n1  Whats weightless, visible to the naked eye, an...  amoeba     vision   \n2  what is weightless, and colorless. . but when ...    hole  measuring   \n3  What is lighter then a feather, can be seen by...    hole       find   \n4  I am always Hungery, I must always be Fed.  th...    cyan       rust   \n\n  choice3  choice4  answer  \n0    hole     rice       2  \n1    hole  hydride       2  \n2    heft    color       0  \n3    dust   sclera       0  \n4  maroon    flame       3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>choice1</th>\n      <th>choice2</th>\n      <th>choice3</th>\n      <th>choice4</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What gets smaller as it gets fuller?</td>\n      <td>bit</td>\n      <td>put</td>\n      <td>hole</td>\n      <td>rice</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Whats weightless, visible to the naked eye, an...</td>\n      <td>amoeba</td>\n      <td>vision</td>\n      <td>hole</td>\n      <td>hydride</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>what is weightless, and colorless. . but when ...</td>\n      <td>hole</td>\n      <td>measuring</td>\n      <td>heft</td>\n      <td>color</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is lighter then a feather, can be seen by...</td>\n      <td>hole</td>\n      <td>find</td>\n      <td>dust</td>\n      <td>sclera</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I am always Hungery, I must always be Fed.  th...</td>\n      <td>cyan</td>\n      <td>rust</td>\n      <td>maroon</td>\n      <td>flame</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"question = convert_sentences_to_tokens(data[\"question\"], eng_tokenizer)\nchoice1 = convert_sentences_to_tokens(data[\"choice1\"], eng_tokenizer)\nchoice2 = convert_sentences_to_tokens(data[\"choice2\"], eng_tokenizer)\nchoice3 = convert_sentences_to_tokens(data[\"choice3\"], eng_tokenizer)\nchoice4 = convert_sentences_to_tokens(data[\"choice4\"], eng_tokenizer)\nlabels = data[\"answer\"].to_numpy().astype(np.uint8)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T01:51:26.838045Z","iopub.execute_input":"2023-11-05T01:51:26.838847Z","iopub.status.idle":"2023-11-05T01:51:28.387518Z","shell.execute_reply.started":"2023-11-05T01:51:26.838811Z","shell.execute_reply":"2023-11-05T01:51:28.386593Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"del riddle_data, sen_data, word_data, data","metadata":{"execution":{"iopub.status.busy":"2023-11-05T01:51:28.388794Z","iopub.execute_input":"2023-11-05T01:51:28.389154Z","iopub.status.idle":"2023-11-05T01:51:28.393853Z","shell.execute_reply.started":"2023-11-05T01:51:28.389123Z","shell.execute_reply":"2023-11-05T01:51:28.392831Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class TrainDataset(DataLoader):\n    def __init__(self, question, choice1, choice2, choice3, choice4, label, randomize_place=False):\n        self.randomize_place = randomize_place\n        self.question = np.array(question, dtype=object)\n        self.choice1 = np.array(choice1, dtype=object)\n        self.choice2 = np.array(choice2, dtype=object)\n        self.choice3 = np.array(choice3, dtype=object)\n        self.choice4 = np.array(choice4, dtype=object)\n        self.label = np.array(label)\n    \n    def __len__(self):\n        return self.question.shape[0]\n    \n    def __getitem__(self, idx):\n        question = torch.tensor([word2idx.get(word, 3) for word in self.question[idx]])\n        choice1 = torch.tensor([word2idx.get(word, 3) for word in self.choice1[idx]])\n        choice2 = torch.tensor([word2idx.get(word, 3) for word in self.choice2[idx]])\n        choice3 = torch.tensor([word2idx.get(word, 3) for word in self.choice3[idx]])\n        choice4 = torch.tensor([word2idx.get(word, 3) for word in self.choice4[idx]])\n        if self.randomize_place:\n            ridx = np.argsort(np.random.randint(0, 256, 4))\n            label = torch.tensor([ridx[self.label[idx]]])\n            choice1, choice2, choice3, choice4 = np.array([choice1, choice2, choice3, choice4], dtype=object)[ridx]\n        else:\n            label = torch.tensor([self.label[idx]])\n        return question, choice1, choice2, choice3, choice4, label\n    \n    \nclass TestDataset(DataLoader):\n    def __init__(self, question, choice1, choice2, choice3, choice4, label=None):\n        self.question = np.array(question, dtype=object)\n        self.choice1 = np.array(choice1, dtype=object)\n        self.choice2 = np.array(choice2, dtype=object)\n        self.choice3 = np.array(choice3, dtype=object)\n        self.choice4 = np.array(choice4, dtype=object)\n        if label is not None:\n            self.label = np.array(label, dtype=object)\n        else:\n            self.label = None\n    \n    def __len__(self):\n        return self.question.shape[0]\n    \n    def __getitem__(self, idx):\n        question = torch.tensor([word2idx.get(word, 3) for word in self.question[idx]])\n        choice1 = torch.tensor([word2idx.get(word, 3) for word in self.choice1[idx]])\n        choice2 = torch.tensor([word2idx.get(word, 3) for word in self.choice2[idx]])\n        choice3 = torch.tensor([word2idx.get(word, 3) for word in self.choice3[idx]])\n        choice4 = torch.tensor([word2idx.get(word, 3) for word in self.choice4[idx]])\n        if self.label is not None:\n            label = torch.tensor([self.label[idx]])\n        else:\n            label = torch.tensor([0])\n        return question, choice1, choice2, choice3, choice4, label\n    \ndef pad_collate(batch):\n    (a, b, c, d, e, f) = zip(*batch)\n    a = nn.utils.rnn.pad_sequence(a, batch_first=True, padding_value=2)\n    b = nn.utils.rnn.pad_sequence(b, batch_first=True, padding_value=2)\n    c = nn.utils.rnn.pad_sequence(c, batch_first=True, padding_value=2)\n    d = nn.utils.rnn.pad_sequence(d, batch_first=True, padding_value=2)\n    e = nn.utils.rnn.pad_sequence(e, batch_first=True, padding_value=2)\n    f = torch.tensor(f)\n    return a, b, c, d, e, f\n\ndef test_pad_collate(batch):\n    (a, b, c, d, e) = zip(*batch)\n    a = nn.utils.rnn.pad_sequence(a, batch_first=True, padding_value=2)\n    b = nn.utils.rnn.pad_sequence(b, batch_first=True, padding_value=2)\n    c = nn.utils.rnn.pad_sequence(c, batch_first=True, padding_value=2)\n    d = nn.utils.rnn.pad_sequence(d, batch_first=True, padding_value=2)\n    e = nn.utils.rnn.pad_sequence(e, batch_first=True, padding_value=2)\n    return a, b, c, d, e","metadata":{"execution":{"iopub.status.busy":"2023-11-05T01:51:28.395295Z","iopub.execute_input":"2023-11-05T01:51:28.395621Z","iopub.status.idle":"2023-11-05T01:51:28.427786Z","shell.execute_reply.started":"2023-11-05T01:51:28.395590Z","shell.execute_reply":"2023-11-05T01:51:28.426578Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, d_model, dropout=DROPOUT, max_len=5000):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        position = torch.arange(max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n        pe = torch.zeros(1, max_len, d_model)\n        pe[0, :, 0::2] = torch.sin(position * div_term)\n        pe[0, :, 1::2] = torch.cos(position * div_term)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + self.pe[0, :x.size(1)]\n        return self.dropout(x)\n\n\nclass BrainTeaserModel(nn.Module):\n    def __init__(self, \n                 vocab_size=VOCAB_SIZE, \n                 embedding_dim=EMBEDDING_DIM, \n                 num_layers=NUM_LAYERS, \n                 num_heads=NUM_HEADS, \n                 dropout=DROPOUT, \n                 embed_mat=None, \n                 freeze=True,\n                 n_class=4,\n                 batch_first=True):\n        super().__init__()\n        \n        self.vocab_size = vocab_size\n        self.embedding_dim = embedding_dim\n        self.num_layers = num_layers\n        self.num_heads = num_heads\n        self.dropout_rate = dropout\n        self.freeze=freeze\n        self.n_class=n_class\n        self.batch_first=True\n        \n        if embed_mat is None:\n            self.embeddings = nn.Embedding(self.vocab_size, self.embedding_dim, padding_idx=2).to(\"cpu\")\n        else:\n            self.embeddings = nn.Embedding.from_pretrained(embed_mat, padding_idx=2, freeze=self.freeze).to(\"cpu\")\n        self.pos_embeddings = PositionalEncoding(self.embedding_dim, dropout=self.dropout_rate).to(DEVICE)\n\n        self.encoder_layer = nn.TransformerEncoderLayer(self.embedding_dim, nhead=self.num_heads, dropout=self.dropout_rate, batch_first=self.batch_first)\n        self.decoder_layer = nn.TransformerDecoderLayer(self.embedding_dim, nhead=self.num_heads, dropout=self.dropout_rate, batch_first=self.batch_first)\n        self.encoder1 = nn.TransformerEncoder(self.encoder_layer, self.num_layers).to(DEVICE)\n        self.decoder1 = nn.TransformerDecoder(self.decoder_layer, self.num_layers).to(DEVICE)\n        self.decoder2 = nn.TransformerDecoder(self.decoder_layer, self.num_layers).to(DEVICE)\n        self.decoder3 = nn.TransformerDecoder(self.decoder_layer, self.num_layers).to(DEVICE)\n        self.decoder4 = nn.TransformerDecoder(self.decoder_layer, self.num_layers).to(DEVICE)\n        self.linear1 = nn.LazyLinear(self.n_class).to(DEVICE)\n        \n    def forward(self, a, b, c, d, e):\n        a = self.pos_embeddings(self.embeddings(a.cpu()).cuda())\n        b = self.pos_embeddings(self.embeddings(b.cpu()).cuda())\n        c = self.pos_embeddings(self.embeddings(c.cpu()).cuda())\n        d = self.pos_embeddings(self.embeddings(d.cpu()).cuda())\n        e = self.pos_embeddings(self.embeddings(e.cpu()).cuda())\n        \n        a = self.encoder1(a)\n        b = self.decoder1(b, a).mean(dim=1)\n        c = self.decoder2(c, a).mean(dim=1)\n        d = self.decoder3(d, a).mean(dim=1)\n        e = self.decoder4(e, a).mean(dim=1)\n        x = torch.cat([b, c, d, e], 1)\n        x = self.linear1(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-05T01:51:28.431440Z","iopub.execute_input":"2023-11-05T01:51:28.431775Z","iopub.status.idle":"2023-11-05T01:51:28.453650Z","shell.execute_reply.started":"2023-11-05T01:51:28.431736Z","shell.execute_reply":"2023-11-05T01:51:28.452476Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = BrainTeaserModel(vocab_size=VOCAB_SIZE, \n                         embedding_dim=EMBEDDING_DIM, \n                         num_layers=NUM_LAYERS, \n                         num_heads=NUM_HEADS, \n                         dropout=DROPOUT, \n                         embed_mat=emb_mat, \n                         freeze=True, \n                         batch_first=True)\nmodel.load_state_dict(torch.load(\"brain-teaser-3.pth\"))\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\ncriterion = nn.CrossEntropyLoss()\ndataset = TrainDataset(question, choice1, choice2, choice3, choice4, labels, randomize_place=False)\nsampler = torch.utils.data.RandomSampler(dataset, num_samples=50000)\ntraining_data = DataLoader(dataset, batch_size=5, collate_fn=pad_collate, sampler=sampler)\naccuracy = Accuracy(task=\"multiclass\", num_classes=4).to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T01:52:11.883132Z","iopub.execute_input":"2023-11-05T01:52:11.884029Z","iopub.status.idle":"2023-11-05T01:52:28.054765Z","shell.execute_reply.started":"2023-11-05T01:52:11.883992Z","shell.execute_reply":"2023-11-05T01:52:28.052660Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n  warnings.warn('Lazy modules are a new feature under heavy development '\n","output_type":"stream"}]},{"cell_type":"code","source":"EPOCHS=1000\nfor epoch in range(1, EPOCHS):\n    postfix = {\"loss\": 0, \"accuracy\": 0}\n    loss_val = 0\n    acc_val = 0\n    bar = tqdm(training_data, desc=f'Epoch {epoch}', postfix=postfix)\n    for idx, (A, B, C, D, E, F) in enumerate(bar):\n        A = A.to(DEVICE)\n        B = B.to(DEVICE)\n        C = C.to(DEVICE)\n        D = D.to(DEVICE)\n        E = E.to(DEVICE)\n        F = F.to(DEVICE)\n\n        model.train()\n        optimizer.zero_grad()\n        preds = model(A, B, C, D, E)\n        loss = criterion(preds, F.long())\n        loss.backward()\n        optimizer.step()\n\n        model.eval()\n        with torch.inference_mode():\n            if not np.isnan(loss.item()):\n                loss_val += loss.item()\n            acc_val += accuracy(preds, F).item()\n            postfix[\"loss\"] = loss_val / (idx + 1)\n            postfix[\"accuracy\"] = acc_val / (idx + 1)\n        bar.set_postfix(postfix)\n    torch.save(model.state_dict(), f\"brain-teaser-3.pth\")","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-11-05T02:00:54.849361Z","iopub.execute_input":"2023-11-05T02:00:54.849826Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Epoch 1: 100%|| 10000/10000 [13:49<00:00, 12.06it/s, loss=0.419, accuracy=0.835]\nEpoch 2: 100%|| 9966/10000 [13:46<00:02, 12.26it/s, loss=0.389, accuracy=0.847]","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), f\"brain-teaser-3.pth\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation","metadata":{}},{"cell_type":"code","source":"val_data = np.load(\"/kaggle/input/cs779-brainteaser/WP_eval_data_for_practice.npy\", allow_pickle=True)\nval_data = pd.DataFrame.from_records(val_data)\nval_data[[\"choice1\", \"choice2\", \"choice3\", \"choice4\"]] = np.array(val_data[\"choice_list\"].to_list())\nval_data = val_data.drop([\"choice_list\"], axis=1)\nval_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-05T01:55:00.595850Z","iopub.execute_input":"2023-11-05T01:55:00.596252Z","iopub.status.idle":"2023-11-05T01:55:00.623471Z","shell.execute_reply.started":"2023-11-05T01:55:00.596207Z","shell.execute_reply":"2023-11-05T01:55:00.622261Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                            question       choice1  \\\n0                     What kind of nut has no shell?     A peanut.   \n1                    Which nut doesn't have a shell?   A Doughnut.   \n2       Which type of bell doesn't make a sound?\\n\\n  A fire bell.   \n3        What does a stone become when in the water?  A whetstone.   \n4  What changes a stone makes when submerged in w...  A whetstone.   \n\n        choice2       choice3         choice4  \n0   A Doughnut.     A walnut.  None of above.  \n1     A walnut.     A peanut.  None of above.  \n2   A cow bell.   A Bluebell.  None of above.  \n3   A limestone  A sandstone.  None of above.  \n4  A sandstone.   A limestone  None of above.  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>choice1</th>\n      <th>choice2</th>\n      <th>choice3</th>\n      <th>choice4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What kind of nut has no shell?</td>\n      <td>A peanut.</td>\n      <td>A Doughnut.</td>\n      <td>A walnut.</td>\n      <td>None of above.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Which nut doesn't have a shell?</td>\n      <td>A Doughnut.</td>\n      <td>A walnut.</td>\n      <td>A peanut.</td>\n      <td>None of above.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Which type of bell doesn't make a sound?\\n\\n</td>\n      <td>A fire bell.</td>\n      <td>A cow bell.</td>\n      <td>A Bluebell.</td>\n      <td>None of above.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What does a stone become when in the water?</td>\n      <td>A whetstone.</td>\n      <td>A limestone</td>\n      <td>A sandstone.</td>\n      <td>None of above.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What changes a stone makes when submerged in w...</td>\n      <td>A whetstone.</td>\n      <td>A sandstone.</td>\n      <td>A limestone</td>\n      <td>None of above.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"val_question = convert_sentences_to_tokens(val_data[\"question\"], eng_tokenizer)\nval_choice1 = convert_sentences_to_tokens(val_data[\"choice1\"], eng_tokenizer)\nval_choice2 = convert_sentences_to_tokens(val_data[\"choice2\"], eng_tokenizer)\nval_choice3 = convert_sentences_to_tokens(val_data[\"choice3\"], eng_tokenizer)\nval_choice4 = convert_sentences_to_tokens(val_data[\"choice4\"], eng_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T01:55:01.598319Z","iopub.execute_input":"2023-11-05T01:55:01.599003Z","iopub.status.idle":"2023-11-05T01:55:01.622141Z","shell.execute_reply.started":"2023-11-05T01:55:01.598959Z","shell.execute_reply":"2023-11-05T01:55:01.621234Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"val_dataset = TestDataset(val_question, val_choice1, val_choice2, val_choice3, val_choice4)\nval_data = DataLoader(val_dataset, batch_size=5, collate_fn=pad_collate)\n\ndata = []\nbar = tqdm(val_data)\nacc = 0\nfor idx, (A, B, C, D, E, F) in enumerate(bar):\n    A = A.to(DEVICE)\n    B = B.to(DEVICE)\n    C = C.to(DEVICE)\n    D = D.to(DEVICE)\n    E = E.to(DEVICE)\n    F = F.to(DEVICE)\n    \n    preds = model(A, B, C, D, E)\n    preds = preds.argmax(1)\n    \n    for i in range(len(preds)):\n        q = convert_to_sentence(A[i].cpu().numpy(), idx2word)\n        c1 = convert_to_sentence(B[i].cpu().numpy(), idx2word)\n        c2 = convert_to_sentence(C[i].cpu().numpy(), idx2word)\n        c3 = convert_to_sentence(D[i].cpu().numpy(), idx2word)\n        c4 = convert_to_sentence(E[i].cpu().numpy(), idx2word)\n#         print(f\"Question: {q}\\n1. {c1}\\n2. {c2}\\n3. {c3}\\n4. {c4}\")\n#         print(f\"Prediction: {preds[i].item()+1}\\n\\n\")\n        data.append(str(preds[i].item()))","metadata":{"execution":{"iopub.status.busy":"2023-11-05T01:55:03.954177Z","iopub.execute_input":"2023-11-05T01:55:03.954934Z","iopub.status.idle":"2023-11-05T01:55:04.745681Z","shell.execute_reply.started":"2023-11-05T01:55:03.954895Z","shell.execute_reply":"2023-11-05T01:55:04.744756Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"100%|| 24/24 [00:00<00:00, 30.84it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"with open(\"answer_word.txt\", \"w\") as f:\n    f.write(\"\\n\".join(data))","metadata":{"execution":{"iopub.status.busy":"2023-11-05T01:55:08.394956Z","iopub.execute_input":"2023-11-05T01:55:08.395336Z","iopub.status.idle":"2023-11-05T01:55:08.401035Z","shell.execute_reply.started":"2023-11-05T01:55:08.395306Z","shell.execute_reply":"2023-11-05T01:55:08.400003Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}